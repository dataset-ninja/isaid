The authors of the **iSAID** dataset have introduced the first benchmark dataset for instance segmentation in aerial imagery, which merges instance-level object detection and pixel-level segmentation tasks. It contains 655,451 object instances spanning 15 different categories across 2,806 high-resolution images. Precise per-pixel annotations have been provided for each instance, ensuring accurate localization for detailed scene analysis. Compared to existing small-scale aerial image-based instance segmentation datasets, iSAID boasts 15 times the number of object categories and 5 times the number of instances.

The authors' primary goal is to encourage advancements in aerial imagery for Earth observation. While datasets for object detection and semantic labeling have been introduced, they do not offer per-pixel accurate labeling for each object instance in aerial images, making them unsuitable for instance segmentation tasks. Publicly available instance segmentation datasets typically focus on a single object category, limiting their applicability. In contrast, iSAID addresses these limitations by providing a comprehensive and large-scale dataset suitable for real-world applications in complex aerial scenes.

To create this instance segmentation dataset, the authors have utilized the [DOTA dataset](https://captain-whu.github.io/DOTA/index.html) (also [available at dninja](https://datasetninja.com/dota)) as a basis, which contains 2,806 images collected from multiple sensors and platforms to reduce bias. However, DOTA originally only provided bounding box annotations for object detection, making it unsuitable for accurate instance segmentation. To ensure accuracy and completeness, the iSAID dataset has been independently annotated from scratch, resulting in a substantial increase in the number of instances compared to the original DOTA dataset.

It's worth noting that instance segmentation in aerial images presents unique challenges compared to standard image datasets. Aerial images typically offer less object detail, smaller sizes, and different viewpoints. Existing aerial image datasets are often annotated with bounding boxes or point labels, which coarsely localize object instances. In contrast, iSAID provides a large number of instances accurately marked with masks, denoting their exact locations in images.

<img src="https://github.com/dataset-ninja/surgical-scene-segmentation-in-robotic-gastrectomy/assets/78355358/b7a75a99-2460-4a3e-b46a-5290e04204f9" alt="image" width="800">

<span style="font-size: smaller; font-style: italic;">"Statistics of classes and instances in iSAID. (a) Histogram of the number of instances per class (sorted by frequency). (b) Histogram of number of instances per image. (c) Histogram of number of classes per image. (d) Number of instances vs. instances per image (comparison of our dataset with other large-scale conventional datasets). The size of the circle denotes the number of categories, e.g., big circle represents the presence of large number of object categories."</span>

To ensure the quality and consistency of annotations, the authors have implemented a comprehensive annotation pipeline, including annotation guidelines: 1) All clearly visible objects of the 15 categories must be annotated; 2) Segmentation masks for each instance should match its visual margin in the image; 3) Images should be zoomed in or out, when necessary, to obtain annotations with refined boundaries; 4) Cases of unclear/difficult objects should be reported to the team supervisors and then discussed to get annotations with high confidence; 5) All work should be done at a single facility using the same software. The professional annotators have been trained, and a rigorous assessment protocol has been used to select the best annotators for the task. 

<img src="https://github.com/dataset-ninja/surgical-scene-segmentation-in-robotic-gastrectomy/assets/78355358/3edf7675-1afc-4833-bceb-ae039461d4a5" alt="image" width="400">

<span style="font-size: smaller; font-style: italic;">Boxplot depicting the range of areas for each object category. The size of objects varies greatly both among and across classes.</span>

Quality control procedures have been applied: 1) The labelers were asked to examine their own annotated images and correct issues like double labels, false labels, missing objects and inaccurate boundaries. 2) The annotators reviewed the work of other peers on rotational basis. In this stage, object masks for each class were cropped and placed in one specific directory, so that the annotation errors could be easily identified and corrected. 3) The supervisory team randomly sampled 70% images (around 2000) and analyzed their quality. 4) A team of experts sampled 20% images (around 500) and ensured the quality of annotations. In case of problems, the annotations were iteratively send back to the annotators for refinement until the experts were satisfied by the labels. 5) Finally, several statistics (e.g., instance areas, aspect ratios, etc.) were computed.

<img src="https://github.com/dataset-ninja/surgical-scene-segmentation-in-robotic-gastrectomy/assets/78355358/f5d551a8-e486-45f4-adbe-0aa5e310e766" alt="image" width="400">

<span style="font-size: smaller; font-style: italic;">Statistics of images and instances in iSAID. (a) Ratio between areas of largest and smallest object shows the huge variation in scale.(b) shows that instances in iSAID exhibit large variation in aspect ratio.</span>

iSAID statistics reveal its unique properties, such as high spatial resolution (ranges from 800 to 13, 000 in width), a large number of instances per image (655,451 annotated instances of 15 categories), significant variations in object size (objects in the range 10 to 144 pixels as small, 144 to 1024 pixels as medium, and 1024 and above as large. The percentage of small, medium and large objects in iSAID is 52.0, 33.7 and 9.7, respectively), aspect ratio (eaching up to 90 (2.4 in average)), and the presence of various object categories. These characteristics distinguish iSAID from other existing datasets and emphasize its potential for real-world applications in aerial imagery analysis. The dataset also offers various statistics regarding image resolution, instance count, object areas, and aspect ratios, highlighting its suitability for handling small, medium, and large objects in aerial scenes.

In summary, the authors have created the iSAID dataset, addressing the limitations of existing aerial image datasets and providing a valuable resource for instance segmentation in complex aerial imagery analysis.
